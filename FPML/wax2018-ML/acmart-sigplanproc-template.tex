%% For double-blind review submission, w/o CCS and ACM Reference (max submission space)
\documentclass[sigplan,review,anonymous=false]{acmart}\settopmatter{printfolios=true,printccs=false,printacmref=false}
%% For double-blind review submission, w/ CCS and ACM Reference
%\documentclass[sigplan,review,anonymous]{acmart}\settopmatter{printfolios=true}
%% For single-blind review submission, w/o CCS and ACM Reference (max submission space)
%\documentclass[sigplan,review]{acmart}\settopmatter{printfolios=true,printccs=false,printacmref=false}
%% For single-blind review submission, w/ CCS and ACM Reference
%\documentclass[sigplan,review]{acmart}\settopmatter{printfolios=true}
%% For final camera-ready submission, w/ required CCS and ACM Reference
%\documentclass[sigplan]{acmart}\settopmatter{}


%% Conference information
%% Supplied to authors by publisher for camera-ready submission;
%% use defaults for review submission.

\acmConference[]{}
\acmYear{}
\acmISBN{} % \acmISBN{978-x-xxxx-xxxx-x/YY/MM}
\acmDOI{} % \acmDOI{10.1145/nnnnnnn.nnnnnnn}
\startPage{1}

%% Copyright information
%% Supplied to authors (based on authors' rights management selection;
%% see authors.acm.org) by publisher for camera-ready submission;
%% use 'none' for review submission.
\setcopyright{none}
%\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
%\setcopyright{rightsretained}
\copyrightyear{}           %% If different from \acmYear

%% Bibliography style
\bibliographystyle{ACM-Reference-Format}
%% Citation style
%\citestyle{acmauthoryear}  %% For author/year citations
%\citestyle{acmnumeric}     %% For numeric citations
%\setcitestyle{nosort}      %% With 'acmnumeric', to disable automatic
                            %% sorting of references within a single citation;
                            %% e.g., \cite{Smith99,Carpenter05,Baker12}
                            %% rendered as [14,5,2] rather than [2,5,14].
%\setcitesyle{nocompress}   %% With 'acmnumeric', to disable automatic
                            %% compression of sequential references within a
                            %% single citation;
                            %% e.g., \cite{Baker12,Baker14,Baker16}
                            %% rendered as [2,3,4] rather than [2-4].


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Note: Authors migrating a paper from traditional SIGPLAN
%% proceedings format to PACMPL format must update the
%% '\documentclass' and topmatter commands above; see
%% 'acmart-pacmpl-template.tex'.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%% Some recommended packages.
\usepackage{booktabs}   %% For formal tables:
                        %% http://ctan.org/pkg/booktabs
\usepackage{subcaption} %% For complex figures with subfigures/subcaptions
                        %% http://ctan.org/pkg/subcaption
\usepackage{lmodern}

\begin{document}

%% Title information
\title[Short Title]{Measuring accuracy and performance of Perceptron and SVM algorithm under different FP precisions}         %% [Short Title] is optional;
                                        %% when present, will be used in
                                        %% header instead of Full Title.
\titlenote{Both Vanilla and Average variants of the Perceptron algorithm}             %% \titlenote is optional;
                                        %% can be repeated if necessary;
                                        %% contents suppressed with 'anonymous'
\subtitle{Subtitle}                     %% \subtitle is optional
\subtitlenote{with sudddddbtitle note}       %% \subtitlenote is optional;
                                        %% can be repeated if necessary;
                                        %% contents suppressed with 'anonymous'


%% Author information
%% Contents and number of authors suppressed with 'anonymous'.
%% Each author should be introduced by \author, followed by
%% \authornote (optional), \orcid (optional), \affiliation, and
%% \email.
%% An author may have multiple affiliations and/or emails; repeat the
%% appropriate command.
%% Many elements are not rendered, but should be provided for metadata
%% extraction tools.

%% Author with single affiliation.
\author{First1 Last1}
\authornote{with author1 note}          %% \authornote is optional;
                                        %% can be repeated if necessary
\orcid{nnnn-nnnn-nnnn-nnnn}             %% \orcid is optional
\affiliation{
  \position{Position1}
  \department{Department1}              %% \department is recommended
  \institution{Institution1}            %% \institution is required
  \streetaddress{Street1 Address1}
  \city{City1}
  \state{State1}
  \postcode{Post-Code1}
  \country{Country1}                    %% \country is recommended
}
\email{first1.last1@inst1.edu}          %% \email is recommended

%% Author with two affiliations and emails.
\author{First2 Last2}
\authornote{with author2 note}          %% \authornote is optional;
                                        %% can be repeated if necessary
\orcid{nnnn-nnnn-nnnn-nnnn}             %% \orcid is optional
\affiliation{
  \position{Position2a}
  \department{Department2a}             %% \department is recommended
  \institution{Institution2a}           %% \institution is required
  \streetaddress{Street2a Address2a}
  \city{City2a}
  \state{State2a}
  \postcode{Post-Code2a}
  \country{Country2a}                   %% \country is recommended
}
\email{first2.last2@inst2a.com}         %% \email is recommended
\affiliation{
  \position{Position2b}
  \department{Department2b}             %% \department is recommended
  \institution{Institution2b}           %% \institution is required
  \streetaddress{Street3b Address2b}
  \city{City2b}
  \state{State2b}
  \postcode{Post-Code2b}
  \country{Country2b}                   %% \country is recommended
}
\email{first2.last2@inst2b.org}         %% \email is recommended


%% Abstract
%% Note: \begin{abstract}...\end{abstract} environment must come
%% before \maketitle command
\begin{abstract}
Perceptron and SVM algortithm are two well known linear predictors. They are both mistake bound algorithm in the sense that when a mistake happen a correctino is applied to the the weight vector. The weight vector is the for both the algorithm is used al predictor of samples. 
Both the dot product and the update of the these two algortihm is performed in double precision. The main goal of this work is to analyse what is the impact of the FP precision adopted for the dataset, computation and test, of the final accuracy of the algorithm. Our analysis want to span the really poor value of the floating point range, and compare the results of these computations with respect to well known IEEE defined standard: single and double precision.\ldots. $-1$
\end{abstract}


%% 2012 ACM Computing Classification System (CSS) concepts
%% Generate at 'http://dl.acm.org/ccs/ccs.cfm'.
\begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10011007.10011006.10011008</concept_id>
<concept_desc>Software and its engineering~General programming languages</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10003456.10003457.10003521.10003525</concept_id>
<concept_desc>Social and professional topics~History of programming languages</concept_desc>
<concept_significance>300</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Software and its engineering~General programming languages}
\ccsdesc[300]{Social and professional topics~History of programming languages}
%% End of generated code


%% Keywords
%% comma separated list
\keywords{keyword1, keyword2, keyword3}  %% \keywords are mandatory in final camera-ready submission


%% \maketitle
%% Note: \maketitle command must come after title commands, author
%% commands, abstract environment, Computing Classification System
%% environment and commands, and keywords command.
\maketitle

\section{Introduction}
Many times a floating point analyzer is applied to a black box algorithm to detect the minimal configuration of each floating point instruction that minimize the final error of the algorithm. In particular the goal of these tools is to produce such a configuration that achieve the input value. These techniques allow both static or dynamic approach where the second one produces better results in terms of accuracy of the solution, because that particular computation was tested al runtime. Part of the analysis is definitely to apply the discovered configuration to an evaluation procedure that verify that the user defined requests are respected.

The comparison between static and dynamic procedure solved in favour of dynamic one because this kind of analysis is definitely ill- conditioned: the input of the analysis (eg. the dataset) impacts on the precision to adopt in the algorithm. Basically, static analysis shows excellent result when the analysis goal is to detect when a behavior exists or not, but when it is time to express the quality of the solution 'testing analysis' returns better results: because the quality of the solution is tested on an evaluation procedure. Dynamic analysis applied to Floating point procedure maintains few 'ghost' executions at runtime that replicate the behaviour of the program under a different floating point precision. Other times the code is injected into the binary of the program and the candidate result is again evaluated. Many heuristics and optimization exists to span the whole spectrum of the floating point precisions (from 1 to 52 bits for the mantissa representation) using binary search or limiting the reseach from single to double precision (from 23 to 52 bits for mantissa).

Our analysis admire and look forward these FP analyzers, and our goal is not to detect the minimal FP configuration of Perceptron and SVM such that the evaluation step is confirmed, but to analyze what are the behaviors of the accuracy of such predictors for really poor FP precision computations. In particular we want to compare the accuracy in case from poor value of floating point precision (from 2 to 10 bits) and compare them to well know (expensive) single and double standards. Most of the times FP analyzer arbitrarily fixed the range to span of all the possible floating point precision until double (all double configuration represent the worst case in terms of FP efficiency and energy consumption). For Perceptron and SVM variants, our work aim to be a preliminary step in the detection of the bounds of the range to analyze.

The main impact of such work is on the precision adopted to represent data in a dataset. Most of the times predictors act on a dataset when tuples represent real characters. For this reasons they need to be discretized. A common question is how many bits of mantissa and exponent need to be adopted to represent/store these value in the dataset. Minimize this precision, while still maintaining accurate values for the accuracy of the predictor ($\frac{Correct.Classification}{Tot.classification}$) quantities produce enormous saving in terms of energy consumption, computational effort, and memory savage.

Thanks to floating point representation real numbers can be discretized in the machine using: the sign of the number, the significant also called mantissa and an exponent. The real value is then discretized with $(-1)^{sign} \cdot significand \cdot 2^{exponent}$. The floating point representation is part of the IEEE 754 that includes two well known representations among others: single precision (1bit sign, 23bits mantissa, 8bits exponent) and double precision (1bit sign, 23bits mantissa, 8bits exponent). These two are the most common used representation for fp computations. It has been showed in [] that most of the time the way the total number of bits is splitted in mantissa and exponent (1 sign always) it is not usefull and better results can be obtained by reassigning the number of bits in different ways\cite{softfloat}
 
FP representation, sign,exp,mantissa,IEEE, single, double\\
Energy Consumption, execution time\\
Why this work.\\
Introduce Perceptron and SVM and why they are the target of this work.

\section{Methods}
What are we looking for?\\
splitting the analysis in PrecisionDataset, PrecisionComputation, Precision Test.
For each one explain what are its goals. 
\section{Requirements}
Dataset, MPFR, softfloat, hardware adopted, library for graphs. 
\section{Results}
Show best result: 3 graphs with 5 bits, 23, 51.
\section{Conclusions}
interesting behaviours showed by decision methods. Dataset precisions seems to do not impact;
Test with few bits shows some interesting area in the graph..

Text of paper \ldots


%% Acknowledgments
\begin{acks}                            %% acks environment is optional
                                        %% contents suppressed with 'anonymous'
  %% Commands \grantsponsor{<sponsorID>}{<name>}{<url>} and
  %% \grantnum[<url>]{<sponsorID>}{<number>} should be used to
  %% acknowledge financial support and will be used by metadata
  %% extraction tools.
  This material is based upon work supported by the
  \grantsponsor{GS100000001}{National Science
    Foundation}{http://dx.doi.org/10.13039/100000001} under Grant
  No.~\grantnum{GS100000001}{nnnnnnn} and Grant
  No.~\grantnum{GS100000001}{mmmmmmm}.  Any opinions, findings, and
  conclusions or recommendations expressed in this material are those
  of the author and do not necessarily reflect the views of the
  National Science Foundation.
\end{acks}


%% Bibliography
\bibliography{bibfile}


%% Appendix
\appendix
\section{Appendix}

Text of appendix \ldots

\end{document}
